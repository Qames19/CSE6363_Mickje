{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_pos_encoding(n_position, dim):\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(10000, 2 * (hid_idx // 2) / dim)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_j) for hid_j in range(dim)]\n",
    "    sinusoidal_encoding = torch.tensor([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoidal_encoding[:, 0::2] = torch.sin(sinusoidal_encoding[:, 0::2])  # dim 2i\n",
    "    sinusoidal_encoding[:, 1::2] = torch.cos(sinusoidal_encoding[:, 1::2])  # dim 2i+1\n",
    "    return sinusoidal_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7bd5aace09413d871468a8d3d5d082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc00b7c6423e41d9ab39c6fd648ac776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52765fce8d48419ab23e52d701efd875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83daafbacab446f6a7aff76d0c17e6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a1a4d0ba7d44ac98d5adb9000dd8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595dfa456c7948c1bdaeb3c93b5728d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen2.5-0.5B\"\n",
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "sequence1 = \"Naomi went to the store.\"\n",
    "sequence2 = \"Naomi went to the store to buy some reaction mass pellets.\"\n",
    "tokens1 = tok(sequence1, return_tensors=\"pt\")[\"input_ids\"]\n",
    "embeddings1 = model.embed_tokens(tokens1)\n",
    "tokens2 = tok(sequence2, return_tensors=\"pt\")[\"input_ids\"]\n",
    "embeddings2 = model.embed_tokens(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7]) torch.Size([1, 7, 896])\n",
      "torch.Size([1, 13]) torch.Size([1, 13, 896])\n",
      "torch.Size([7, 896]) torch.Size([13, 896])\n",
      "pos 0 same:  True\n",
      "pos 1 same:  True\n",
      "pos 2 same:  True\n",
      "pos 3 same:  True\n",
      "pos 4 same:  True\n",
      "pos 5 same:  True\n",
      "pos 6 same:  True\n",
      "Distances between consecutive positions for encoding 1\n",
      "pos 0 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 1 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 2 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 3 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 4 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 5 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "Distances between consecutive positions for encoding 2\n",
      "pos 0 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 1 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 2 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 3 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 4 diff:  tensor(4.8777, dtype=torch.float64)\n",
      "pos 5 diff:  tensor(4.8777, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(tokens1.shape, embeddings1.shape)\n",
    "print(tokens2.shape, embeddings2.shape)\n",
    "\n",
    "# Generate position encodings for each sequence\n",
    "pos_enc1 = sinusoidal_pos_encoding(tokens1.shape[1], model.config.hidden_size)\n",
    "pos_enc2 = sinusoidal_pos_encoding(tokens2.shape[1], model.config.hidden_size)\n",
    "\n",
    "print(pos_enc1.shape, pos_enc2.shape)\n",
    "\n",
    "# compare the positional encodings beteween the two sequences\n",
    "for i in range(pos_enc1.shape[0]):\n",
    "    print(f\"pos {i} same: \", torch.allclose(pos_enc1[i], pos_enc2[i]))\n",
    "\n",
    "# show distances beween i and i+1 for each encoding for the first 7 positions\n",
    "print(\"Distances between consecutive positions for encoding 1\")\n",
    "for i in range(6):\n",
    "    print(f\"pos {i} diff: \", torch.dist(pos_enc1[i], pos_enc1[i+1]))\n",
    "\n",
    "# show distances beween i and i+1 for each encoding for the first 7 positions\n",
    "print(\"Distances between consecutive positions for encoding 2\")\n",
    "for i in range(6):\n",
    "    print(f\"pos {i} diff: \", torch.dist(pos_enc2[i], pos_enc2[i+1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6363",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
